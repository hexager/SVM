{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"titanic.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = data.drop(['Name','PassengerId', 'Ticket', 'Cabin', 'Survived'], axis=1)\n",
    "y = data['Survived']\n",
    "data_cat =data1.select_dtypes(include=['object'])  \n",
    "data_num1 =data1.select_dtypes(include=['number'])\n",
    "data_num = data_num1.fillna(data_num1.mean())\n",
    "mean = data_num.mean(axis=0)\n",
    "std = data_num.std(axis=0)\n",
    "data_num_norm = (data_num - mean) / std\n",
    "\n",
    "data_cat_proc = pd.get_dummies(data_cat, drop_first=True) \n",
    "boolean_cols = data_cat_proc.columns[data_cat_proc.dtypes == 'bool']\n",
    "data_cat_proc[boolean_cols] = data_cat_proc[boolean_cols].astype(int)\n",
    "data_proc = pd.concat([data_num_norm, data_cat_proc], axis=1) \n",
    "plt.figure(figsize=(12,10))\n",
    "data_for = pd.concat([data_proc, y], axis=1) \n",
    "cor = data_for.corr()\n",
    "sns.heatmap(cor, annot=True, cmap = 'viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing PCA\n",
    "### Forming covariance matrix, sorting them in order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_matrix = data_proc.cov()\n",
    "eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)\n",
    "\n",
    "sorted_indices = np.argsort(eigenvalues)[::-1]\n",
    "sorted_eigenvalues = eigenvalues[sorted_indices]\n",
    "sorted_eigenvectors = eigenvectors[:, sorted_indices]\n",
    "\n",
    "print(f'Eigenvalues of P:\\n{sorted_eigenvalues}\\n\\nEigenvectors of P\\n{sorted_eigenvectors}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Scree Plot to see importance of eigenvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sorted_eigenvalues)\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Eigenvalue')\n",
    "plt.title('Scree Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting Principle components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 7\n",
    "principal_components = eigenvectors[:, :k]\n",
    "pca_features = pd.DataFrame(np.dot(data_proc, principal_components))\n",
    "print(pca_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Train and Test data for both normal and PCA features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.3\n",
    "\n",
    "n_samples = data_proc.shape[0]\n",
    "n_samplespca = pca_features.shape[0]\n",
    "\n",
    "n_test_samples = int(n_samples * test_size)\n",
    "n_test_samplespca = int(n_samplespca * test_size)\n",
    "\n",
    "indices = np.arange(n_samples)\n",
    "indicespca = np.arange(n_samplespca)\n",
    "np.random.shuffle(indices)\n",
    "np.random.shuffle(indicespca)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_indices = indices[n_test_samples:]\n",
    "test_indices = indices[:n_test_samples]\n",
    "train_indicespca = indicespca[n_test_samplespca:]\n",
    "test_indicespca = indicespca[:n_test_samplespca]\n",
    "\n",
    "X_train = data_proc.iloc[train_indices]\n",
    "y_train = y.iloc[train_indices]\n",
    "X_trainpca = pca_features.iloc[train_indicespca]\n",
    "y_trainpca = y.iloc[train_indicespca]\n",
    "\n",
    "\n",
    "\n",
    "X_test = data_proc.iloc[test_indices]\n",
    "y_test = y.iloc[test_indices]\n",
    "X_testpca = pca_features.iloc[test_indicespca]\n",
    "y_testpca = y.iloc[test_indicespca]\n",
    "ll_values = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Functions for Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "def log_loss(y_true, y_pred):\n",
    "    # Calculate the log loss\n",
    "    epsilon = 1e-15\n",
    "    loss = -np.mean(y_true * np.log(y_pred + epsilon) + (1 - y_true) * np.log(1 - y_pred + epsilon))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Class for Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self, lr = 0.1, n_iters = 700):\n",
    "        self.lr = lr\n",
    "        self.n_iters = n_iters\n",
    "        self.weights = None\n",
    "        self.bias = 0\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "        prev_mse = float('inf')\n",
    "        for i in range(self.n_iters):\n",
    "            linearpred = np.dot(X, self.weights) + self.bias\n",
    "            y_predicted = sigmoid(linearpred)\n",
    "            delw = (1/n_samples)*np.dot(X.T, (y_predicted - y))\n",
    "            delb = (1/n_samples)*np.sum(y_predicted - y)\n",
    "            self.weights = self.weights - self.lr*delw\n",
    "            self.bias = self.bias - self.lr*delb\n",
    "            loglossv = log_loss(y, y_predicted)\n",
    "            ll_values.append(loglossv)\n",
    "#            if i > 0:\n",
    "#                if prev_mse - mse < 1e3:\n",
    "#                    break\n",
    "#            prev_mse = mse\n",
    "    def predict(self, X):\n",
    "        linearpred = np.dot(X, self.weights) + self.bias\n",
    "        y_predicted = sigmoid(linearpred)\n",
    "        predicted = [0 if y<=0.5 else 1 for y in y_predicted]\n",
    "        return predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining evaluation parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(tp,fp,tn,fn):\n",
    "    precision = tp / (tp + fp) if tp + fp != 0 else 0\n",
    "    recall = tp / (tp + fn) if tp + fn != 0 else 0\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    f1 = 2 * precision * recall / (precision + recall) if precision + recall != 0 else 0\n",
    "    return f1\n",
    "def confusion_matrix(tp, fp, tn, fn):\n",
    "    data = [[tn, fp], [fn, tp]]\n",
    "    plt.imshow(data, cmap='Blues')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xticks([0, 1], ['Negative', 'Positive'])\n",
    "    plt.yticks([0, 1], ['Negative', 'Positive'])\n",
    "\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            if i == 0 and j == 0:\n",
    "                plt.text(j, i, f'TN: {tn}', ha='center', va='center', color='white')\n",
    "            elif i == 0 and j == 1:\n",
    "                plt.text(j, i, f'FP: {fp}', ha='center', va='center', color='black')\n",
    "            elif i == 1 and j == 0:\n",
    "                plt.text(j, i, f'FN: {fn}', ha='center', va='center', color='black')\n",
    "            elif i == 1 and j == 1:\n",
    "                plt.text(j, i, f'TP: {tp}', ha='center', va='center', color='black')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executing Logistic Regression on Normal Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)\n",
    "predictions = classifier.predict(X_test)\n",
    "def accuracy(y_pred,y_test):\n",
    "    return np.sum(y_pred==y_test)/len(y_test)\n",
    "predictions_array = np.array(predictions)\n",
    "y_test_array = np.array(y_test)\n",
    "tp = np.sum((y_test_array == 1) & (predictions_array == 1))\n",
    "fp = np.sum((y_test_array == 0) & (predictions_array == 1))\n",
    "tn = np.sum((y_test_array == 0) & (predictions_array == 0))\n",
    "fn = np.sum((y_test_array == 1) & (predictions_array == 0)) \n",
    "plt.show()\n",
    "plt.plot(range(1, len(ll_values) + 1), ll_values)\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Log Loss\")\n",
    "plt.title(\"Log Loss over Iterations\")\n",
    "plt.show()\n",
    "f1 = f1_score(tp,fp,tn,fn)\n",
    "print(\"F1 score:\",f1)\n",
    "confusion_matrix(tp,fp,tn,fn)\n",
    "ll_values = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executing Logistic Regression on Dataset with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier2 = LogisticRegression(lr=0.1)\n",
    "classifier2.fit(X_trainpca, y_trainpca)\n",
    "predictionspca = classifier2.predict(X_testpca)\n",
    "predictions_arraypca = np.array(predictionspca)\n",
    "y_test_arraypca = np.array(y_testpca)\n",
    "tp = np.sum((y_test_arraypca == 1) & (predictions_arraypca == 1))\n",
    "fp = np.sum((y_test_arraypca == 0) & (predictions_arraypca == 1))\n",
    "tn = np.sum((y_test_arraypca == 0) & (predictions_arraypca == 0))\n",
    "fn = np.sum((y_test_arraypca == 1) & (predictions_arraypca == 0))\n",
    "plt.show()\n",
    "plt.plot(range(1, len(ll_values) + 1), ll_values)\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Log Loss\")\n",
    "plt.title(\"Log Loss over Iterations\")\n",
    "plt.show()\n",
    "f1 = f1_score(tp,fp,tn,fn)\n",
    "print(\"F1 score:\",f1)\n",
    "confusion_matrix(tp,fp,tn,fn)\n",
    "ll_values = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Class for Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SupportVectorMachine:\n",
    "    def __init__(self, reg_strength=0.1, n_iters=700, lr=0.1):\n",
    "        self.reg_strength = reg_strength\n",
    "        self.n_iters = n_iters\n",
    "        self.lr = lr\n",
    "        self.weights = None\n",
    "        self.bias = 0\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "        y = np.array(y)\n",
    "        X = np.array(X)\n",
    "        y = np.where(y == 0, -1, 1)\n",
    "\n",
    "        for epoch in range(self.n_iters):\n",
    "            linear_output = np.dot(X, self.weights) + self.bias\n",
    "            distances = 1 - y * linear_output\n",
    "            dw = np.zeros(n_features)\n",
    "            db = 0\n",
    "\n",
    "            for i in range(n_samples):\n",
    "                if distances[i] > 0:\n",
    "                    dw += -y[i] * X[i]\n",
    "                    db += -y[i]\n",
    "            dw = dw / n_samples + (self.reg_strength * self.weights / n_samples)\n",
    "            db = db / n_samples\n",
    "            self.weights -= self.lr * dw\n",
    "            self.bias -= self.lr * db\n",
    "            cost = (1 / n_samples) * np.sum(np.maximum(0, 1 - y * (np.dot(X, self.weights) + self.bias))) + (self.reg_strength / 2) * np.sum(self.weights ** 2)\n",
    "            if epoch % 100 == 0 or epoch == self.n_iters - 1:\n",
    "                print(f\"Epoch {epoch}/{self.n_iters} | Cost1: {cost}\")\n",
    "            ll_values.append(cost)\n",
    "\n",
    "    def predict(self, X):\n",
    "        linear_output = np.dot(X, self.weights) + self.bias\n",
    "        return np.where(linear_output >= 0, 1, 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executing Support Vector Machine Classification on Normal Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svmobj = SupportVectorMachine(lr=0.017)\n",
    "svmobj.fit(X_train, y_train)\n",
    "predictions = svmobj.predict(X_test)\n",
    "predictions_array = np.array(predictions)\n",
    "y_test_array = np.array(y_test)\n",
    "tp = np.sum((y_test_array == 1) & (predictions_array == 1))\n",
    "fp = np.sum((y_test_array == 0) & (predictions_array == 1))\n",
    "tn = np.sum((y_test_array == 0) & (predictions_array == 0))\n",
    "fn = np.sum((y_test_array == 1) & (predictions_array == 0))\n",
    "plt.show()\n",
    "plt.plot(range(1, len(ll_values) + 1), ll_values)\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Log Loss\")\n",
    "plt.title(\"Cost over Iterations\")\n",
    "plt.show()\n",
    "f1 = f1_score(tp,fp,tn,fn)\n",
    "print(\"F1 score:\",f1)\n",
    "confusion_matrix(tp,fp,tn,fn)\n",
    "ll_values = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executing Support Vector Machine Classification on Dataset with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svmobj2 = SupportVectorMachine(lr=0.015,reg_strength=0.05)\n",
    "svmobj2.fit(X_trainpca, y_trainpca)\n",
    "predictionspca = svmobj2.predict(X_testpca)\n",
    "predictions_arraypca = np.array(predictionspca)\n",
    "y_test_arraypca = np.array(y_testpca)\n",
    "tp = np.sum((y_test_arraypca == 1) & (predictions_arraypca == 1))\n",
    "fp = np.sum((y_test_arraypca == 0) & (predictions_arraypca == 1))\n",
    "tn = np.sum((y_test_arraypca == 0) & (predictions_arraypca == 0))\n",
    "fn = np.sum((y_test_arraypca == 1) & (predictions_arraypca == 0))\n",
    "plt.show()\n",
    "plt.plot(range(1, len(ll_values) + 1), ll_values)\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Log Loss\")\n",
    "plt.title(\"Cost over Iterations\")\n",
    "plt.show()\n",
    "f1 = f1_score(tp,fp,tn,fn)\n",
    "print(\"F1 score:\",f1)\n",
    "confusion_matrix(tp,fp,tn,fn)\n",
    "ll_values = []"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
